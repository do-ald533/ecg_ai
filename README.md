# ECG Classification with CNN

Projeto de classificaÃ§Ã£o de sinais de eletrocardiograma (ECG) utilizando redes neurais convolucionais 1D (CNN-1D) para detectar mÃºltiplas condiÃ§Ãµes cardÃ­acas.

## ğŸ“‹ DescriÃ§Ã£o

Este projeto implementa um modelo de deep learning para classificaÃ§Ã£o multi-label de sinais de ECG de 12 derivaÃ§Ãµes. O modelo Ã© capaz de identificar as seguintes condiÃ§Ãµes:

- **1dAVb**: Bloqueio atrioventricular de primeiro grau
- **RBBB**: Bloqueio de ramo direito
- **LBBB**: Bloqueio de ramo esquerdo
- **SB**: Bradicardia sinusal
- **AF**: FibrilaÃ§Ã£o atrial
- **ST**: AlteraÃ§Ã£o do segmento ST
- **normal_ecg**: ECG normal

## ğŸ—ï¸ Estrutura do Projeto

```
ecg/
â”œâ”€â”€ ecgai/                         # Pacote principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                  # Sistema de configuraÃ§Ã£o
â”‚   â”œâ”€â”€ data/                      # MÃ³dulo de dados
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset.py             # Dataset + DataLoaders
â”‚   â”‚   â””â”€â”€ preprocess.py          # PrÃ©-processamento
â”‚   â”œâ”€â”€ models/                    # MÃ³dulo de modelos
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ cnn.py                 # Arquitetura CNN-1D
â”‚   â”œâ”€â”€ training/                  # MÃ³dulo de treinamento
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py             # Classe Trainer
â”‚   â”‚   â””â”€â”€ metrics.py             # MÃ©tricas
â”‚   â””â”€â”€ utils/                     # MÃ³dulo de utilitÃ¡rios
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ checkpoint.py          # Checkpoints
â”‚       â”œâ”€â”€ distributed.py         # FunÃ§Ãµes DDP
â”‚       â”œâ”€â”€ helpers.py             # Helpers gerais
â”‚       â””â”€â”€ logging.py             # Sistema de logs
â”œâ”€â”€ notebooks/                     # Jupyter notebooks
â”‚   â”œâ”€â”€ test_h5.ipynb             # Testes com HDF5
â”‚   â””â”€â”€ train.ipynb               # Notebook de treino
â”œâ”€â”€ main.py                        # ğŸ‘‰ Ponto de entrada Ãºnico
â”œâ”€â”€ config.yaml                    # ConfiguraÃ§Ã£o
â”œâ”€â”€ pyproject.toml                 # DependÃªncias + config (ruff, mypy, taskipy)
â””â”€â”€ README.md                     # Este arquivo
```

## ğŸš€ InstalaÃ§Ã£o

### 1. Instalar uv (package manager moderno)

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

Ou no macOS/Linux:
```bash
brew install uv
```

### 2. Clone o repositÃ³rio

```bash
git clone <repository-url>
cd ecg
```

### 3. Instalar dependÃªncias

```bash
uv sync
```

Isso irÃ¡:
- Criar `.venv` automaticamente
- Instalar todas as dependÃªncias do `pyproject.toml`
- Gerar `uv.lock` para reprodutibilidade

### 4. Ativar ambiente (opcional)

```bash
source .venv/bin/activate
```

Ou use `uv run` para executar comandos diretamente sem ativar.

## ğŸ“Š PreparaÃ§Ã£o dos Dados

O projeto espera dados em formato HDF5 com a seguinte estrutura:
- DiretÃ³rio `dataset/unzipped/` com arquivos `exams_part*.hdf5`
- Arquivo `dataset/exams.csv` com metadados e labels

### PrÃ©-processamento

Execute o prÃ©-processamento:

```bash
uv run task preprocess
```

Ou com argumentos customizados:
```bash
uv run python main.py preprocess \
    --data-dir dataset/unzipped \
    --csv-path dataset/exams.csv \
    --output-dir processed_npz
```

Este script:
- Normaliza os sinais por derivaÃ§Ã£o (z-score)
- Divide os dados em train/val/test por paciente (80/10/10)
- Salva arquivos `.npz` comprimidos em `processed_npz/`

## ğŸ¯ Treinamento

### ConfiguraÃ§Ã£o

Edite o arquivo `config.yaml` para ajustar hiperparÃ¢metros:

```yaml
training:
  batch_size: 32
  epochs: 50
  learning_rate: 0.001
  patience: 7
```

### Executando o Treinamento

#### Com uv diretamente:
```bash
uv run python main.py train --config config.yaml
uv run torchrun --standalone --nproc_per_node=4 main.py train --config config.yaml
```

#### Com taskipy (recomendado):
```bash
uv run task train
uv run task train-ddp
uv run task preprocess
```

#### Ver tasks disponÃ­veis:
```bash
uv run task --list
```

## ğŸ› ï¸ Desenvolvimento

### Tasks DisponÃ­veis (taskipy)

O projeto usa **taskipy** para automatizar tarefas comuns:

```bash
uv run task --list
```

#### Qualidade de CÃ³digo
```bash
uv run task format       # Formata cÃ³digo com ruff
uv run task lint         # Verifica cÃ³digo com ruff
uv run task lint-fix     # Corrige problemas automaticamente
uv run task type-check   # Verifica tipos com mypy
uv run task check        # Roda lint + type-check
uv run task fix          # Corrige e formata tudo
```

#### Treinamento
```bash
uv run task train        # Treina modelo (single-process)
uv run task train-ddp    # Treina modelo (distribuÃ­do 4 GPUs/cores)
uv run task preprocess   # PrÃ©-processa dados
```

#### Limpeza
```bash
uv run task clean        # Remove caches e arquivos temporÃ¡rios
uv run task clean-all    # Limpeza completa incluindo .venv
```

### âœ¨ Melhorias e OtimizaÃ§Ãµes

#### Ferramentas Modernas
- **uv**: Package manager ultra-rÃ¡pido
- **ruff**: Linting e formatting em Rust (10-100x mais rÃ¡pido)
- **mypy**: Type checking estÃ¡tico
- **taskipy**: Gerenciamento de tasks simplificado

#### Arquitetura Modular
- **ConfiguraÃ§Ã£o Externa**: YAML editÃ¡vel sem tocar no cÃ³digo
- **Classe Trainer**: Gerenciamento profissional do loop de treino
- **Type Hints**: CÃ³digo totalmente tipado para melhor IDE support
- **Logging Estruturado**: Logs claros e informativos

#### Performance
- **I/O Otimizado**: Memory-mapped files (~30% mais rÃ¡pido)
- **Auto-detect Workers**: NÃºmero Ã³timo de workers automaticamente
- **Gradient Clipping**: Previne explosÃ£o de gradientes
- **Mixed Precision**: Suporte a AMP para GPUs

#### Qualidade
- **MÃ©tricas Detalhadas**: F1, Precision, Recall, AUROC, AP
- **Checkpoints Inteligentes**: Salva best e last automaticamente
- **Early Stopping**: Para quando nÃ£o hÃ¡ mais melhoria
- **Class Weights**: Balanceamento automÃ¡tico de classes

## ğŸ§  Arquitetura do Modelo

O modelo `ECG_CNN1D` consiste em:
- 3 blocos convolucionais (32 â†’ 64 â†’ 128 filtros)
- Batch Normalization e ReLU apÃ³s cada convoluÃ§Ã£o
- Global Average Pooling
- Camadas densas com Dropout (0.3)
- SaÃ­da com Sigmoid para classificaÃ§Ã£o multi-label

**Input**: `(batch, 4096, 12)` - 4096 pontos temporais Ã— 12 derivaÃ§Ãµes  
**Output**: `(batch, 7)` - Probabilidades para cada condiÃ§Ã£o

## ğŸ“ˆ MÃ©tricas

O modelo Ã© avaliado usando:
- **F1-Score** (macro e micro)
- **Precision** (macro e micro)
- **Recall** (macro e micro)
- **AUROC** (macro e micro)
- **Average Precision** (PR-AUC)

MÃ©tricas sÃ£o salvas automaticamente em:
- `checkpoints/training_metrics.csv` - HistÃ³rico completo
- `checkpoints/best_model.pt` - Melhor modelo
- `checkpoints/last_model.pt` - Ãšltimo checkpoint

## ğŸ”§ Requisitos

- Python 3.8+
- uv (package manager)
- PyTorch 2.0+
- CUDA (opcional, para GPU)
- 8GB+ RAM recomendado

### InstalaÃ§Ã£o do uv

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Ajustar HiperparÃ¢metros

Edite `config.yaml` para customizar:

```yaml
training:
  batch_size: 32          # Tamanho do batch
  learning_rate: 0.001    # Learning rate inicial
  patience: 7             # Early stopping patience
  eval_every: 5           # Avaliar a cada N Ã©pocas
  gradient_clip: 1.0      # Clipping de gradientes (null = desabilitado)
  warmup_epochs: 3        # Ã‰pocas de warmup
  use_amp: false          # Mixed precision (apenas GPU)
  compile_model: false    # torch.compile() (PyTorch 2.x)

dataloader:
  num_workers: null       # null = auto-detect
  pin_memory: false       # true para GPU
  prefetch_factor: 2

model:
  dropout_rate: 0.3       # Dropout rate
```

### Usar GPU

Se tiver GPU disponÃ­vel, ajuste:

```yaml
training:
  use_amp: true          # Mixed precision training

dataloader:
  pin_memory: true       # Acelera transferÃªncia CPU->GPU

distributed:
  backend: "nccl"        # Backend otimizado para GPU
```

## ğŸ§ª Testes e ValidaÃ§Ã£o

### Avaliar Modelo Treinado

```python
from ecgai import ECG_CNN1D, Config
from ecgai.utils import load_checkpoint
import torch

# Carrega modelo
config = Config.get_default()
model = ECG_CNN1D(
    n_leads=config.data.num_leads,
    n_classes=len(config.data.labels)
)
load_checkpoint('checkpoints/best_model.pt', model)
model.eval()

# InferÃªncia
with torch.no_grad():
    signal = torch.randn(1, 12, 4096)  # [batch, leads, length]
    output = model(signal)  # Probabilidades [batch, 7]
    
print(f"PrediÃ§Ãµes: {output}")
print(f"Classes: {config.data.labels}")
```

## ğŸ“ Notas

- Os dados originais **nÃ£o** estÃ£o incluÃ­dos no repositÃ³rio
- Modelos treinados (`.pt`) sÃ£o ignorados pelo git
- Logs e mÃ©tricas sÃ£o salvos automaticamente em `checkpoints/`
- Arquivos de backup (`.bak`) sÃ£o ignorados pelo git

## ğŸ“„ LicenÃ§a

[Adicione sua licenÃ§a aqui]

## ğŸ‘¥ Autores

[Adicione os autores aqui]
